import streamlit as st
from ollama import chat
import ollama
import base64
from time import sleep
import json
import random
import pandas as pd
import pickle

## change_beta_save
user_name = 'HIRO'

## set site
st.set_page_config(page_title="HIRO AI",  page_icon='./img/logo.png',layout="centered")

## ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸
if 'user' not in st.session_state:
    st.session_state.user = 'not_login'
if 'generating' not in st.session_state:
    st.session_state.generating = False
if 'check_idx' not in st.session_state:
    st.session_state.check_idx = len(st.session_state.history_name)-1

## ì±„íŒ… ë°ì´í„°ë² ì´ìŠ¤
if 'history_name' not in st.session_state:
    st.session_state.history_name = ['âš¡ìƒˆ ëŒ€í™”1']
if 'history_chathisroty' not in st.session_state:
    st.session_state.history_chathisroty = [[{"role": "system", "content": "Your name is HIRO AI. Your company is HIRO AI. "}]]
if 'history_model' not in st.session_state:
    st.session_state.history_model = ["HIRO 1 mini"]
if 'database' not in st.session_state:
    st.session_state.database = []

# ì „ì²´ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
if st.session_state.history_chathisroty[st.session_state.check_idx]:
    for message in st.session_state.history_chathisroty[st.session_state.check_idx]:
        if message['role'] == 'user':
            st.write(f"### ğŸ« ì‚¬ìš©ì")
            st.write(message['content'])
            st.markdown("---")
        elif message['role'] == 'assistant':
            st.image('./img/logo.png',width=35)
            st.write('')
            if st.session_state.history_model[st.session_state.check_idx] in ['HIRO 1','HIRO 1 mini','HIRO 2','HIRO 3o','HIRO 4o','HIRO dep2']:
                st.write(message['content'])
            elif st.session_state.history_model[st.session_state.check_idx] == 'HIRO dep1':
                t, r = message['content'].split('<THINK_Bar_Space_Id>')
                t = t.lstrip("<think>")
                t = t.rstrip("</think>")
                with st.popover("âš¡ìƒê°ì¤‘..."): st.write(t)
                st.write(r)
            st.markdown(f":violet-badge[âš¡{st.session_state.history_model[st.session_state.check_idx]}]")
            st.markdown("---")

#ë©”ì¸ í˜ì´ì§€
#HIRO1 mini -> gemma3:1b   o
#HIRO1 -> gemma:2b         
#HIRO2 -> exaone3.5:7.8b   o
#HIRO 3o -> gemma3:4b       o
#HIRO 4o -> gemma3:12b      o
#HIRO dep1                  o
#HIRO dep2                  o
if st.session_state.history_model[st.session_state.check_idx] == 'HIRO 3o' or st.session_state.history_model[st.session_state.check_idx] == 'HIRO 4o':
    prompt = st.chat_input("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”.",accept_file=True,file_type=["jpg", "jpeg", "png"])
else:
    prompt = st.chat_input("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”.")

if prompt and prompt != '':
    if st.session_state.generating == True:
        st.toast('ë‹µë³€ì„ ì •ì§€í•˜ì˜€ìŠµë‹ˆë‹¤.')
        st.session_state.generating = False
    else:
        # ë‹µë³€ ì„¤ì •
        st.session_state.generating = True
        
        # ëŒ€í™” ê¸°ë¡ì— ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
        st.session_state.history_chathisroty[st.session_state.check_idx].append({'role': 'user', 'content': prompt})
        
        # ì‚¬ìš©ì ì…ë ¥ì¶”ê°€
        st.write(f"### ğŸ« ì‚¬ìš©ì")
        if st.session_state.history_model[st.session_state.check_idx] in ['HIRO 3o','HIRO 4o']:
            if prompt["files"]:
                st.image(prompt["files"][0],width=100)
        st.write(prompt)
        st.markdown("---")

        # AIë¡œê³ 
        st.image('./img/logo.png',width=35)
        st.write('')
        
        # í™˜ê²½ ì„¤ì •
        with st.spinner("ğŸ“ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê³  ìˆìŠµë‹ˆë‹¤"):
            ## ì œëª© ìƒì„±
            if len(st.session_state.history_chathisroty[st.session_state.check_idx]) == 2:
                stream = chat(model="exaone3.5:7.8b",
                            messages= [{"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ 3ê¸€ì ì´ìƒ 5ë‹¨ì–´ ì´í•˜ë¡œ ì§ˆë¬¸ì— ì œëª©ì„ ìƒì„±í•´ì•¼í•´. ì œëª©ë§Œ ìƒì„±í•´ì„œ ì¤˜ì•¼ í•´."},{"role": "user", "content": prompt}],stream=True)
                title = 'ğŸ‘‰ '
                for chunk in stream:
                    title += chunk.message.content
                st.session_state.history_name[st.session_state.check_idx] = title
                
            ## ì‚¬ìš©ì ì •ë³´
            stream = chat(model="exaone3.5:7.8b",
                        messages= [{"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìê°€ ê¸°ì–µí•´ ë‹¬ë¼ëŠ” ê²ƒ ë˜ëŠ” ê¼­ ê¸°ì–µí•´ì•¼ í•˜ëŠ” ê²ƒ(ì‚¬ìš©ìì— í•™êµ, ê°€ì¡±ê´€ê³„, ì§ì—… ë“±)ë§Œ í•œêµ­ì–´ë¡œ ì§§ê²Œ ì•Œë ¤ì¤˜ì•¼ í•´(ìµœëŒ€ 20ê¸€ì, ì˜ˆ(ì§ˆë¬¸ : ë‚˜ëŠ” ê°œë°œìê°€ ë˜ê³  ì‹¶ì–´ ,ì •ë¦¬: ì‚¬ìš©ìëŠ” ê°œë°œìê°€ ë˜ê¸°ë¥¼ ì›í•œë‹¤.)). ë§Œì•½ì— ê¼­ í•„ìš”í•˜ì§€ ì•Šê±°ë‚˜, ê¸°ì–µí•´ì•¼ í•  ë§Œí•œ ê²ƒì´ ì—†ìœ¼ë©´ ê·¸ëƒ¥ 'Nothing here'ë§Œ ë°˜í™˜í•´"},{"role": "user", "content": prompt}],stream=True)
            dater = ''
            for chunk in stream:
                dater += chunk.message.content
            if dater.strip() != 'Nothing here':
                st.session_state.database.append(dater)
                with st.popover("ğŸ”– ì €ì¥ëœ ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸ë¨"):
                    st.info(f"'{dater}'ê°€ ì¶”ê°€ë¨", icon="â„¹ï¸")
                    df = pd.DataFrame(st.session_state.database, columns=['ë©”ëª¨ë¦¬ ëª©ë¡'])
                    st.write('### ë©”ëª¨ë¦¬ ëª©ë¡')
                    st.dataframe(df.reset_index(drop=True), hide_index=True)
        
        
        
        
        #ëª¨ë¸ë³„ë¡œ ë‹¤ë¥¸ ì‘ë‹µ ìƒì„±
        if st.session_state.history_model[st.session_state.check_idx] in ['HIRO 1','HIRO 1 mini','HIRO 2']:
            placeholder_response = st.empty()
            response_text = ""  
            model = {
                'HIRO 1': 'gemma:2b',
                'HIRO 1 mini': 'gemma3:1b',
                'HIRO 2': 'exaone3.5:7.8b'
            }
            with st.spinner("âœ¨ ì‘ë‹µ ìƒì„±ì„ ëŒ€ê¸°í•˜ê³  ìˆìŠµë‹ˆë‹¤"):    
                ## ì‘ë‹µ ìƒì„±
                stream = chat(
                    model=model[st.session_state.history_model[st.session_state.check_idx]],
                    messages= st.session_state.history_chathisroty[st.session_state.check_idx],
                    stream=True
                )
                for chunk in stream:
                    response_text += chunk.message.content
                    break
            for chunk in stream:
                response_text += chunk.message.content
                placeholder_response.markdown(f"<span style='font-size:16px'>{response_text}</span>", unsafe_allow_html=True)
            st.session_state.history_chathisroty[st.session_state.check_idx].append({'role': 'assistant', 'content': response_text})
        
        elif st.session_state.history_model[st.session_state.check_idx] in ['HIRO 3o','HIRO 4o']:
            placeholder_response = st.empty()
            response_text = ""  
            model = {
                'HIRO 3o': 'gemma3:4b',
                'HIRO 4o': 'gemma3:12b'
            }
            with st.spinner("âœ¨ ì‘ë‹µ ìƒì„±ì„ ëŒ€ê¸°í•˜ê³  ìˆìŠµë‹ˆë‹¤"):    
                ## ì‘ë‹µ ìƒì„±
                if prompt and prompt["files"]:
                    stream = chat(
                        model=model[st.session_state.history_model[st.session_state.check_idx]],
                        messages= st.session_state.history_chathisroty[st.session_state.check_idx],
                        image=prompt["files"][0],
                        stream=True
                    )
                else:
                    image = None
                    stream = chat(
                        model=model[st.session_state.history_model[st.session_state.check_idx]],
                        messages= st.session_state.history_chathisroty[st.session_state.check_idx],
                        stream=True
                    )
                for chunk in stream:
                    response_text += chunk.message.content
                    break
            for chunk in stream:
                response_text += chunk.message.content
                placeholder_response.markdown(f"<span style='font-size:16px'>{response_text}</span>", unsafe_allow_html=True)
            st.session_state.history_chathisroty[st.session_state.check_idx].append({'role': 'assistant', 'content': response_text})
        
        
        
        
        
        
        
        #####################################################################################   
        elif st.session_state.history_model[st.session_state.check_idx] == 'HIRO dep1':
            with st.spinner("âœ¨ ì‘ë‹µ ìƒì„±ì„ ëŒ€ê¸°í•˜ê³  ìˆìŠµë‹ˆë‹¤"):
                stream = chat(
                    model="DeepSeek-R1",
                    messages= st.session_state.history_chathisroty[st.session_state.check_idx],
                    stream=True
                )
                with st.popover("âš¡ìƒê°ì¤‘..."):
                    placeholder_think = st.empty()
                placeholder_response = st.empty()
                think_text = ""
                thinking_now = True
                response_text = ""
                for chunk in stream:
                    think_text += chunk.message.content
                    if '</think>' in think_text:
                        thinking_now = False
                    break
            for chunk in stream:
                if thinking_now == False:
                    response_text += chunk.message.content
                    placeholder_response.markdown(f"<span style='font-size:16px'>{response_text}</span>", unsafe_allow_html=True)
                else:
                    think_text += chunk.message.content
                    placeholder_think.markdown(f"<span style='font-size:16px;'>{think_text}</span>", unsafe_allow_html=True)
                    if '</think>' in think_text:
                        thinking_now = False
            
            # AIì˜ ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            st.session_state.history_chathisroty[st.session_state.check_idx].append({'role': 'assistant', 'content': think_text+'<THINK_Bar_Space_Id>'+response_text})
        
        
        
        
        
        
        
        #####################################################################################   
        elif st.session_state.history_model[st.session_state.check_idx] == "HIRO dep2":
            ## --í† ëŒ€ ë§ˆë ¨--
            with st.popover("âš¡ì‘ë‹µì„ ìƒì„± ì¤‘ ì…ë‹ˆë‹¤..."):
                placeholder_tree = st.empty()
            tree = ''
            stream = chat(model="exaone3.5:7.8b",messages= st.session_state.history_chathisroty[st.session_state.check_idx],stream=True)
            for chunk in stream:
                tree += chunk.message.content
                placeholder_tree.markdown(f"<span style='font-size:16px;'>{tree}</span>", unsafe_allow_html=True)
            
            # --ë³´ì™„í•˜ê¸°--
            with st.popover("ğŸ“ ì‘ë‹µì˜ ë³´ì™„ì ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤..."):
                placeholder_rerun = st.empty()
            rerun = ''
            st.session_state.history_chathisroty[st.session_state.check_idx].append({'role': 'user', 'content':f'"{tree}"ì´ê²ƒì€ ì‚¬ìš©ìê°€ {prompt}ì´ë¼ í–ˆì„ ë•Œì— ë‹µë³€ì¸ë°, ìˆ˜ì •í•´ì•¼í•  ë¶€ë¶„ë§Œ ì•Œë ¤ì¤˜!'})
            stream = chat(model="exaone3.5:7.8b",
                          messages= st.session_state.history_chathisroty[st.session_state.check_idx]
                          ,stream=True)
            for chunk in stream:
                rerun += chunk.message.content
                placeholder_rerun.markdown(f"<span style='font-size:16px;'>{rerun}</span>", unsafe_allow_html=True)
            st.session_state.history_chathisroty[st.session_state.check_idx].pop()
            
            #--ì™„ì„±í•˜ê¸°--
            placeholder_answer = st.empty()
            answer = ''
            st.session_state.history_chathisroty[st.session_state.check_idx].append({'role': 'user', 'content':f'ì „ì— ë„ˆê°€ {tree}ì´ë¼ê³  ì‘ë‹µì„ í•´ ì£¼ì—ˆëŠ”ë°, ì‚¬ìš©ìëŠ” {rerun}ë¼ê³  ìˆ˜ì •ì„ í•´ ë‹¬ë˜. ê·¸ëŸ¬ë‹ˆê¹Œ ì´ê²ƒì„ ê°€ì§€ê³  ìµœì¢…ì ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•´ì¤˜. ì£¼ì œëŠ” {prompt}ì•¼'})
            stream = chat(model="exaone3.5:7.8b",
                          messages= st.session_state.history_chathisroty[st.session_state.check_idx]
                          ,stream=True)
            for chunk in stream:
                answer += chunk.message.content
                placeholder_answer.markdown(f"<span style='font-size:16px;'>{answer}</span>", unsafe_allow_html=True)
            st.session_state.history_chathisroty[st.session_state.check_idx].pop()
            st.session_state.history_chathisroty[st.session_state.check_idx].append({'role': 'assistant', 'content':answer})
            
            
        
        
        st.markdown(f":violet-badge[âš¡{st.session_state.history_model[st.session_state.check_idx]}]")
        st.markdown('----')
        st.session_state.generating = False


elif st.session_state.history_chathisroty[st.session_state.check_idx][-1]['role'] == 'system':
    ## ë””ìì¸ ì§€ì •
    st.markdown(
        """
        <style>
        .gradient-text {
            text-align: center;
            margin-top: 30vh;
            font-size: 3em;
            font-weight: bold;
            background: linear-gradient(270deg, #9d00ff, #0055ff, #00ffee, #9d00ff);
            background-size: 600% 600%;
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            animation: gradient-flow 6s ease infinite;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    # ë¬¸êµ¬
    st.markdown(
        f"""
        <div class="gradient-text">ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤, {user_name}ë‹˜</div>
        """,
        unsafe_allow_html=True
    )